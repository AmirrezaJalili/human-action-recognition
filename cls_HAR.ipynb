{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pgTOlvo5Rhkf",
        "outputId": "f3baa810-080e-4908-d4b1-86ef334c87ff"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Access Google Drive Folder\n",
        "import os\n",
        "os.chdir(\"gdrive/MyDrive\")"
      ],
      "metadata": {
        "id": "FTTbFRT8RqxK"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Create YOLOv8 root folder\n",
        "!mkdir yolov8-cls-HAR"
      ],
      "metadata": {
        "id": "Yt4oH97XRq4w"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Go to YOLOv8 Classification root folder\n",
        "%cd yolov8-cls-HAR"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZPPYozo0Rq_t",
        "outputId": "6b7f6565-386e-4705-9062-e7477e643c8b"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov8-cls-HAR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Install YOLOv8\n",
        "%pip install ultralytics\n",
        "\n",
        "import ultralytics\n",
        "ultralytics.checks()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4owpSs6ERrGg",
        "outputId": "c4df6d9d-b5fb-4666-9d6c-9ff5728bb859"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.8 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "Setup complete âœ… (2 CPUs, 12.7 GB RAM, 28.8/78.2 GB disk)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Download YOLOv8 Classification models\n",
        "!wget https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-cls.pt"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W5ASmG-hRrNo",
        "outputId": "d908f209-85f3-4286-d1e0-44dd030eed3c"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-05-05 10:25:41--  https://github.com/ultralytics/assets/releases/download/v0.0.0/yolov8l-cls.pt\n",
            "Resolving github.com (github.com)... 140.82.116.4\n",
            "Connecting to github.com (github.com)|140.82.116.4|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/2ceae889-423c-4980-949e-c802399fdddc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240505T102541Z&X-Amz-Expires=300&X-Amz-Signature=76828bc02e7a726fb5722cc1e871a3a84a6a5ff2bed6611f23532855aac50f74&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8l-cls.pt&response-content-type=application%2Foctet-stream [following]\n",
            "--2024-05-05 10:25:41--  https://objects.githubusercontent.com/github-production-release-asset-2e65be/521807533/2ceae889-423c-4980-949e-c802399fdddc?X-Amz-Algorithm=AWS4-HMAC-SHA256&X-Amz-Credential=AKIAVCODYLSA53PQK4ZA%2F20240505%2Fus-east-1%2Fs3%2Faws4_request&X-Amz-Date=20240505T102541Z&X-Amz-Expires=300&X-Amz-Signature=76828bc02e7a726fb5722cc1e871a3a84a6a5ff2bed6611f23532855aac50f74&X-Amz-SignedHeaders=host&actor_id=0&key_id=0&repo_id=521807533&response-content-disposition=attachment%3B%20filename%3Dyolov8l-cls.pt&response-content-type=application%2Foctet-stream\n",
            "Resolving objects.githubusercontent.com (objects.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to objects.githubusercontent.com (objects.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 75150736 (72M) [application/octet-stream]\n",
            "Saving to: â€˜yolov8l-cls.ptâ€™\n",
            "\n",
            "yolov8l-cls.pt      100%[===================>]  71.67M  64.8MB/s    in 1.1s    \n",
            "\n",
            "2024-05-05 10:25:42 (64.8 MB/s) - â€˜yolov8l-cls.ptâ€™ saved [75150736/75150736]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Dataset\n",
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pr4GQ9lbRrUX",
        "outputId": "b80dd254-23d3-43c3-bba2-06bfd07c36d0"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Unzip Dataset\n",
        "!unzip data/actions_dataset.zip -d ./data"
      ],
      "metadata": {
        "id": "xZcSSoHeRraI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Check Dataset\n",
        "!ls data/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3ygR8pzeSlwy",
        "outputId": "99e90935-5351-464f-c788-095758ec1dde"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "actions_dataset  actions_dataset.zip\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "print(os.getcwd())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLQrlQW9Sqbv",
        "outputId": "a4500185-acc3-4e6d-f5db-6f5e5f0daae1"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov8-cls-HAR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train\n",
        "!yolo classify train model=yolov8l-cls.pt data=/content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset imgsz=224 workers=8 batch=16 device=0 epochs=50 patience=50 name=yolov8_cls_human_action"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LrHoxOJ6SqiD",
        "outputId": "e6954401-590f-4a4c-9965-a85f688d1796"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.8 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "\u001b[34m\u001b[1mengine/trainer: \u001b[0mtask=classify, mode=train, model=yolov8l-cls.pt, data=/content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset, epochs=50, time=None, patience=50, batch=16, imgsz=224, save=True, save_period=-1, cache=False, device=0, workers=8, project=None, name=yolov8_cls_human_action2, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=False, opset=None, workspace=4, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, label_smoothing=0.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs/classify/yolov8_cls_human_action2\n",
            "\u001b[34m\u001b[1mtrain:\u001b[0m /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/train... found 7296 images in 9 classes âœ… \n",
            "\u001b[34m\u001b[1mval:\u001b[0m /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/val... found 912 images in 9 classes âœ… \n",
            "\u001b[34m\u001b[1mtest:\u001b[0m /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test... found 912 images in 9 classes âœ… \n",
            "2024-05-05 10:33:38.817782: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "2024-05-05 10:33:38.817834: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "2024-05-05 10:33:38.835438: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Overriding model.yaml nc=1000 with nc=9\n",
            "\n",
            "                   from  n    params  module                                       arguments                     \n",
            "  0                  -1  1      1856  ultralytics.nn.modules.conv.Conv             [3, 64, 3, 2]                 \n",
            "  1                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
            "  2                  -1  3    279808  ultralytics.nn.modules.block.C2f             [128, 128, 3, True]           \n",
            "  3                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
            "  4                  -1  6   2101248  ultralytics.nn.modules.block.C2f             [256, 256, 6, True]           \n",
            "  5                  -1  1   1180672  ultralytics.nn.modules.conv.Conv             [256, 512, 3, 2]              \n",
            "  6                  -1  6   8396800  ultralytics.nn.modules.block.C2f             [512, 512, 6, True]           \n",
            "  7                  -1  1   4720640  ultralytics.nn.modules.conv.Conv             [512, 1024, 3, 2]             \n",
            "  8                  -1  3  17836032  ultralytics.nn.modules.block.C2f             [1024, 1024, 3, True]         \n",
            "  9                  -1  1   1324809  ultralytics.nn.modules.head.Classify         [1024, 9]                     \n",
            "YOLOv8l-cls summary: 183 layers, 36211273 parameters, 36211273 gradients, 99.1 GFLOPs\n",
            "Transferred 300/302 items from pretrained weights\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mStart with 'tensorboard --logdir runs/classify/yolov8_cls_human_action2', view at http://localhost:6006/\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks with YOLOv8n...\n",
            "Downloading https://github.com/ultralytics/assets/releases/download/v8.2.0/yolov8n.pt to 'yolov8n.pt'...\n",
            "100% 6.23M/6.23M [00:00<00:00, 90.0MB/s]\n",
            "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed âœ…\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mScanning /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/train... 7296 images, 0 corrupt: 100% 7296/7296 [00:38<00:00, 191.34it/s]\n",
            "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/train.cache\n",
            "/usr/lib/python3.10/multiprocessing/popen_fork.py:66: RuntimeWarning: os.fork() was called. os.fork() is incompatible with multithreaded code, and JAX is multithreaded, so this will likely lead to a deadlock.\n",
            "  self.pid = os.fork()\n",
            "\u001b[34m\u001b[1mval: \u001b[0mScanning /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/val... 912 images, 0 corrupt: 100% 912/912 [00:05<00:00, 166.35it/s]\n",
            "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/val.cache\n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
            "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.000714, momentum=0.9) with parameter groups 50 weight(decay=0.0), 51 weight(decay=0.0005), 51 bias(decay=0.0)\n",
            "\u001b[34m\u001b[1mTensorBoard: \u001b[0mmodel graph visualization added âœ…\n",
            "Image sizes 224 train, 224 val\n",
            "Using 2 dataloader workers\n",
            "Logging results to \u001b[1mruns/classify/yolov8_cls_human_action2\u001b[0m\n",
            "Starting training for 50 epochs...\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       1/50      1.66G      2.276         16        224:   2% 7/456 [00:01<01:11,  6.27it/s]Downloading https://ultralytics.com/assets/Arial.ttf to '/root/.config/Ultralytics/Arial.ttf'...\n",
            "       1/50      1.66G      2.282         16        224:   2% 11/456 [00:02<01:27,  5.09it/s]\n",
            "100% 755k/755k [00:00<00:00, 26.2MB/s]\n",
            "       1/50      1.67G      1.257         16        224: 100% 456/456 [01:44<00:00,  4.36it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.30it/s]\n",
            "                   all      0.776      0.984\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       2/50      1.69G     0.9449         16        224: 100% 456/456 [01:38<00:00,  4.64it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.44it/s]\n",
            "                   all      0.753      0.988\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       3/50      1.68G     0.9716         16        224: 100% 456/456 [01:39<00:00,  4.57it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.39it/s]\n",
            "                   all      0.739      0.984\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       4/50      1.67G     0.9482         16        224: 100% 456/456 [01:39<00:00,  4.60it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.35it/s]\n",
            "                   all      0.757      0.986\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       5/50      1.68G     0.8872         16        224: 100% 456/456 [01:38<00:00,  4.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.38it/s]\n",
            "                   all      0.777      0.982\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       6/50      1.68G      0.838         16        224: 100% 456/456 [01:42<00:00,  4.45it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.31it/s]\n",
            "                   all      0.792      0.982\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       7/50      1.68G     0.7793         16        224: 100% 456/456 [01:40<00:00,  4.53it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.33it/s]\n",
            "                   all      0.796       0.99\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       8/50      1.69G     0.7136         16        224: 100% 456/456 [01:39<00:00,  4.58it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:09<00:00,  2.91it/s]\n",
            "                   all      0.791       0.99\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "       9/50      1.69G      0.665         16        224: 100% 456/456 [01:41<00:00,  4.47it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.55it/s]\n",
            "                   all      0.816       0.99\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      10/50      1.68G     0.6332         16        224: 100% 456/456 [01:43<00:00,  4.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:07<00:00,  3.73it/s]\n",
            "                   all      0.814      0.991\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      11/50      1.66G     0.6022         16        224: 100% 456/456 [01:43<00:00,  4.40it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:07<00:00,  3.76it/s]\n",
            "                   all      0.808      0.989\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      12/50      1.68G      0.613         16        224: 100% 456/456 [01:40<00:00,  4.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.35it/s]\n",
            "                   all      0.804      0.986\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      13/50      1.69G     0.5597         16        224: 100% 456/456 [01:39<00:00,  4.56it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.40it/s]\n",
            "                   all      0.812      0.991\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      14/50       1.7G     0.5209         16        224: 100% 456/456 [01:40<00:00,  4.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.43it/s]\n",
            "                   all       0.83      0.989\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      15/50      1.69G     0.5337         16        224: 100% 456/456 [01:40<00:00,  4.54it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:08<00:00,  3.36it/s]\n",
            "                   all       0.83       0.99\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      16/50      1.66G     0.4703         16        224: 100% 456/456 [01:41<00:00,  4.48it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:07<00:00,  3.89it/s]\n",
            "                   all      0.799      0.984\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      17/50      1.69G     0.4615         16        224: 100% 456/456 [01:37<00:00,  4.65it/s]\n",
            "               classes   top1_acc   top5_acc: 100% 29/29 [00:07<00:00,  3.78it/s]\n",
            "                   all       0.84      0.987\n",
            "\n",
            "      Epoch    GPU_mem       loss  Instances       Size\n",
            "      18/50      1.66G     0.4112         16        224:  70% 319/456 [01:11<00:30,  4.45it/s]\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/yolo\", line 8, in <module>\n",
            "    sys.exit(entrypoint())\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/cfg/__init__.py\", line 582, in entrypoint\n",
            "    getattr(model, mode)(**overrides)  # default args from model\n",
            "  File \"/usr/local/lib/python3.10/dist-packages/ultralytics/engine/model.py\", line 673, in train\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test"
      ],
      "metadata": {
        "id": "zgJBQUvjSq6d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.getcwd())"
      ],
      "metadata": {
        "id": "ELA2BPuHcmvq",
        "outputId": "36d4b588-3b1d-45dc-b4ec-07cf96092ae7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/yolov8-cls-HAR\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!yolo predict model=runs/classify/yolov8_cls_human_action2/weights/best.pt source=data/actions_dataset/test save=True save_txt = True"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_h2pSR2JSrAR",
        "outputId": "a1ced98a-7b9c-4887-c38e-77d622eb5e15"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Ultralytics YOLOv8.2.8 ðŸš€ Python-3.10.12 torch-2.2.1+cu121 CUDA:0 (Tesla T4, 15102MiB)\n",
            "YOLOv8l-cls summary (fused): 133 layers, 36196105 parameters, 0 gradients, 98.7 GFLOPs\n",
            "\n",
            "image 1/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/145.jpg: 224x224 sitting 0.99, standing 0.01, laughing 0.00, eating 0.00, drinking 0.00, 10.9ms\n",
            "image 2/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/151.jpg: 224x224 sitting 1.00, standing 0.00, laughing 0.00, drinking 0.00, eating 0.00, 10.9ms\n",
            "image 3/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/155.jpg: 224x224 standing 1.00, sitting 0.00, eating 0.00, laughing 0.00, calling 0.00, 11.9ms\n",
            "image 4/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/168.jpg: 224x224 sitting 0.78, standing 0.22, eating 0.00, laughing 0.00, drinking 0.00, 10.9ms\n",
            "image 5/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/184.jpg: 224x224 sitting 1.00, standing 0.00, laughing 0.00, calling 0.00, using_laptop 0.00, 12.2ms\n",
            "image 6/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/186.jpg: 224x224 sitting 0.72, standing 0.28, sleeping 0.00, drinking 0.00, laughing 0.00, 14.7ms\n",
            "image 7/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/206.jpg: 224x224 standing 1.00, sitting 0.00, texting 0.00, calling 0.00, drinking 0.00, 11.0ms\n",
            "image 8/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/218.jpg: 224x224 standing 1.00, sitting 0.00, drinking 0.00, calling 0.00, eating 0.00, 11.1ms\n",
            "image 9/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/452.jpg: 224x224 standing 1.00, sitting 0.00, laughing 0.00, drinking 0.00, calling 0.00, 11.0ms\n",
            "image 10/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/453.jpg: 224x224 standing 0.55, sitting 0.45, laughing 0.00, using_laptop 0.00, eating 0.00, 11.2ms\n",
            "image 11/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/455.jpg: 224x224 standing 0.92, sitting 0.08, laughing 0.00, drinking 0.00, texting 0.00, 11.7ms\n",
            "image 12/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/459.jpg: 224x224 standing 1.00, sitting 0.00, drinking 0.00, calling 0.00, eating 0.00, 10.9ms\n",
            "image 13/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1047.jpg: 224x224 eating 0.98, texting 0.01, drinking 0.00, laughing 0.00, calling 0.00, 10.9ms\n",
            "image 14/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1390.jpg: 224x224 calling 0.51, texting 0.28, using_laptop 0.20, drinking 0.01, sleeping 0.00, 11.0ms\n",
            "image 15/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1423.jpg: 224x224 calling 0.97, laughing 0.02, texting 0.00, drinking 0.00, eating 0.00, 10.9ms\n",
            "image 16/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1584.jpg: 224x224 sleeping 0.78, sitting 0.09, texting 0.04, drinking 0.04, using_laptop 0.02, 11.8ms\n",
            "image 17/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1587.jpg: 224x224 sleeping 0.90, drinking 0.07, using_laptop 0.01, texting 0.01, laughing 0.01, 11.0ms\n",
            "image 18/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1687.jpg: 224x224 drinking 0.94, texting 0.03, eating 0.03, calling 0.00, using_laptop 0.00, 10.9ms\n",
            "image 19/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1786.jpg: 224x224 sleeping 1.00, texting 0.00, using_laptop 0.00, laughing 0.00, sitting 0.00, 10.9ms\n",
            "image 20/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1873.jpg: 224x224 laughing 1.00, calling 0.00, drinking 0.00, texting 0.00, sleeping 0.00, 11.0ms\n",
            "image 21/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1953.jpg: 224x224 laughing 1.00, calling 0.00, drinking 0.00, texting 0.00, sitting 0.00, 11.1ms\n",
            "image 22/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_1982.jpg: 224x224 laughing 1.00, drinking 0.00, texting 0.00, calling 0.00, sitting 0.00, 11.0ms\n",
            "image 23/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_2167.jpg: 224x224 calling 0.99, texting 0.01, using_laptop 0.00, laughing 0.00, sitting 0.00, 11.0ms\n",
            "image 24/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_3506.jpg: 224x224 drinking 0.99, eating 0.00, laughing 0.00, texting 0.00, sleeping 0.00, 11.0ms\n",
            "image 25/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_36.jpg: 224x224 eating 1.00, sitting 0.00, drinking 0.00, calling 0.00, texting 0.00, 11.0ms\n",
            "image 26/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_3704.jpg: 224x224 drinking 1.00, laughing 0.00, calling 0.00, texting 0.00, using_laptop 0.00, 12.8ms\n",
            "image 27/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_3800.jpg: 224x224 drinking 1.00, texting 0.00, using_laptop 0.00, calling 0.00, sitting 0.00, 11.0ms\n",
            "image 28/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_3879.jpg: 224x224 drinking 1.00, calling 0.00, texting 0.00, using_laptop 0.00, eating 0.00, 10.9ms\n",
            "image 29/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4098.jpg: 224x224 calling 0.47, texting 0.34, drinking 0.18, laughing 0.00, using_laptop 0.00, 10.9ms\n",
            "image 30/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4175.jpg: 224x224 using_laptop 0.35, calling 0.34, texting 0.22, drinking 0.06, sitting 0.01, 10.9ms\n",
            "image 31/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4190.jpg: 224x224 laughing 0.99, calling 0.00, sitting 0.00, drinking 0.00, texting 0.00, 10.9ms\n",
            "image 32/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4243.jpg: 224x224 using_laptop 1.00, texting 0.00, eating 0.00, sitting 0.00, calling 0.00, 10.9ms\n",
            "image 33/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4248.jpg: 224x224 laughing 0.66, calling 0.15, drinking 0.10, texting 0.08, sitting 0.00, 10.9ms\n",
            "image 34/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4294.jpg: 224x224 laughing 0.99, calling 0.01, texting 0.00, eating 0.00, sleeping 0.00, 11.2ms\n",
            "image 35/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4323.jpg: 224x224 using_laptop 0.99, texting 0.01, calling 0.00, sitting 0.00, drinking 0.00, 10.9ms\n",
            "image 36/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4434.jpg: 224x224 texting 0.99, calling 0.01, drinking 0.00, using_laptop 0.00, sitting 0.00, 11.1ms\n",
            "image 37/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4522.jpg: 224x224 using_laptop 1.00, texting 0.00, calling 0.00, eating 0.00, drinking 0.00, 13.0ms\n",
            "image 38/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4629.jpg: 224x224 texting 1.00, using_laptop 0.00, sitting 0.00, calling 0.00, drinking 0.00, 10.9ms\n",
            "image 39/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_4708.jpg: 224x224 using_laptop 0.86, texting 0.12, calling 0.01, sitting 0.01, sleeping 0.00, 10.9ms\n",
            "image 40/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_516.jpg: 224x224 calling 0.82, drinking 0.13, texting 0.02, laughing 0.01, eating 0.01, 11.0ms\n",
            "image 41/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_553.jpg: 224x224 calling 0.91, texting 0.06, eating 0.02, using_laptop 0.00, laughing 0.00, 11.0ms\n",
            "image 42/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_554.jpg: 224x224 calling 0.98, texting 0.02, drinking 0.00, using_laptop 0.00, sitting 0.00, 11.0ms\n",
            "image 43/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_5702.jpg: 224x224 using_laptop 1.00, texting 0.00, calling 0.00, eating 0.00, sitting 0.00, 11.0ms\n",
            "image 44/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_591.jpg: 224x224 calling 0.65, using_laptop 0.30, texting 0.03, sitting 0.01, sleeping 0.00, 11.0ms\n",
            "image 45/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_6013.jpg: 224x224 calling 1.00, texting 0.00, using_laptop 0.00, sitting 0.00, eating 0.00, 11.6ms\n",
            "image 46/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_6431.jpg: 224x224 texting 0.99, sitting 0.00, calling 0.00, drinking 0.00, using_laptop 0.00, 11.0ms\n",
            "image 47/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_6580.jpg: 224x224 texting 0.83, using_laptop 0.15, sleeping 0.01, calling 0.00, drinking 0.00, 10.9ms\n",
            "image 48/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_783.jpg: 224x224 laughing 0.97, drinking 0.02, eating 0.01, texting 0.00, calling 0.00, 11.0ms\n",
            "image 49/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_8179.jpg: 224x224 texting 0.74, using_laptop 0.14, sitting 0.12, sleeping 0.00, eating 0.00, 11.0ms\n",
            "image 50/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_865.jpg: 224x224 eating 1.00, sitting 0.00, laughing 0.00, drinking 0.00, texting 0.00, 12.5ms\n",
            "image 51/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_866.jpg: 224x224 drinking 0.63, eating 0.19, texting 0.08, laughing 0.08, calling 0.01, 11.0ms\n",
            "image 52/52 /content/gdrive/MyDrive/yolov8-cls-HAR/data/actions_dataset/test/Image_973.jpg: 224x224 eating 0.62, drinking 0.34, calling 0.02, using_laptop 0.01, texting 0.00, 10.9ms\n",
            "Speed: 4.8ms preprocess, 11.2ms inference, 0.1ms postprocess per image at shape (1, 3, 224, 224)\n",
            "Results saved to \u001b[1mruns/classify/predict\u001b[0m\n",
            "52 labels saved to runs/classify/predict/labels\n",
            "ðŸ’¡ Learn more at https://docs.ultralytics.com/modes/predict\n"
          ]
        }
      ]
    }
  ]
}